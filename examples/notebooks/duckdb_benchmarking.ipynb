{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-cell",
   "metadata": {},
   "source": [
    "# DuckDB Local Benchmarking with BenchBox\n",
    "\n",
    "This notebook demonstrates comprehensive benchmarking of DuckDB, an embedded analytical database designed for fast analytics on local data.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Running TPC-H and TPC-DS benchmarks with DuckDB\n",
    "- Optimizing memory and threading for performance\n",
    "- Working with different file formats (CSV, Parquet, JSON)\n",
    "- Integrating with pandas DataFrames\n",
    "- Using DuckDB extensions for enhanced capabilities\n",
    "- Comparing persistent vs in-memory performance\n",
    "\n",
    "**Why DuckDB?**\n",
    "- **Embedded**: No server, no configuration - runs in-process\n",
    "- **Fast**: Vectorized execution, optimized for analytics\n",
    "- **Portable**: Single-file database or pure in-memory\n",
    "- **Versatile**: Query CSV/Parquet/JSON files directly\n",
    "- **Zero-cost**: Free and open source\n",
    "\n",
    "**Prerequisites:**\n",
    "- Python 3.8+\n",
    "- Sufficient disk space for test data (~100MB-10GB depending on scale)\n",
    "- Recommended: 4GB+ RAM for larger scale factors\n",
    "\n",
    "**Estimated time:** 5-15 minutes (scale factor 0.01-1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. Installation & Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install-desc",
   "metadata": {},
   "source": [
    "### Install Required Packages\n",
    "\n",
    "Install BenchBox and DuckDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q benchbox duckdb pandas matplotlib seaborn psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import-desc",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "\n",
    "Import BenchBox components and visualization libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# BenchBox imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Visualization imports\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from benchbox.core.config import BenchmarkConfig, DatabaseConfig\n",
    "from benchbox.core.results.exporter import ResultExporter\n",
    "from benchbox.core.results.loader import ResultLoader\n",
    "from benchbox.core.runner import LifecyclePhases, run_benchmark_lifecycle\n",
    "\n",
    "# DuckDB import\n",
    "try:\n",
    "    import duckdb\n",
    "\n",
    "    print(f\"‚úÖ DuckDB {duckdb.__version__} imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error importing DuckDB: {e}\")\n",
    "    print(\"   Install with: pip install duckdb\")\n",
    "\n",
    "# System monitoring\n",
    "try:\n",
    "    import psutil\n",
    "\n",
    "    print(\"‚úÖ psutil imported for system monitoring\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  psutil not available - install for system monitoring: pip install psutil\")\n",
    "    psutil = None\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"\\nüì¶ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-desc",
   "metadata": {},
   "source": [
    "### Configure DuckDB\n",
    "\n",
    "DuckDB offers two modes:\n",
    "\n",
    "**1. In-Memory Mode (Fastest)**\n",
    "- All data stored in RAM\n",
    "- No persistence between sessions\n",
    "- Best for: Quick tests, temporary analysis\n",
    "```python\n",
    "conn = duckdb.connect(':memory:')\n",
    "```\n",
    "\n",
    "**2. Persistent Mode (Recommended)**\n",
    "- Data stored in single database file\n",
    "- Persists between sessions\n",
    "- Best for: Repeated testing, data reuse\n",
    "```python\n",
    "conn = duckdb.connect('benchbox.duckdb')\n",
    "```\n",
    "\n",
    "**Configuration Options:**\n",
    "- **Threads**: Set worker threads (default: all CPU cores)\n",
    "- **Memory**: Limit memory usage (default: 80% of system RAM)\n",
    "- **Temp Directory**: Location for spill-to-disk operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure benchmark settings\n",
    "config = {\n",
    "    \"mode\": \"persistent\",  # or \"memory\"\n",
    "    \"database_file\": \"./benchmark_runs/duckdb/benchbox.duckdb\",\n",
    "    \"threads\": os.cpu_count(),  # Use all CPU cores\n",
    "    \"memory_limit\": \"4GB\",  # Adjust based on your system\n",
    "    \"temp_directory\": \"./benchmark_runs/duckdb/temp\",\n",
    "    # Scale factors to test\n",
    "    \"scale_factors\": [0.01, 0.1, 1.0],  # 10MB, 100MB, 1GB\n",
    "    # Output directory\n",
    "    \"output_dir\": \"./benchmark_results\",\n",
    "}\n",
    "\n",
    "# Create directories\n",
    "Path(config[\"database_file\"]).parent.mkdir(parents=True, exist_ok=True)\n",
    "Path(config[\"temp_directory\"]).mkdir(parents=True, exist_ok=True)\n",
    "Path(config[\"output_dir\"]).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Get system information\n",
    "if psutil:\n",
    "    total_ram = psutil.virtual_memory().total / (1024**3)  # GB\n",
    "    available_ram = psutil.virtual_memory().available / (1024**3)  # GB\n",
    "    print(\"üíª System Information:\")\n",
    "    print(f\"   CPU Cores: {config['threads']}\")\n",
    "    print(f\"   Total RAM: {total_ram:.1f} GB\")\n",
    "    print(f\"   Available RAM: {available_ram:.1f} GB\")\n",
    "    print(f\"   DuckDB Memory Limit: {config['memory_limit']}\")\n",
    "else:\n",
    "    print(\"üíª System Information:\")\n",
    "    print(f\"   CPU Cores: {config['threads']}\")\n",
    "    print(f\"   DuckDB Memory Limit: {config['memory_limit']}\")\n",
    "\n",
    "print(\"\\n‚úÖ Configuration complete\")\n",
    "print(f\"   Mode: {config['mode']}\")\n",
    "if config[\"mode\"] == \"persistent\":\n",
    "    print(f\"   Database: {config['database_file']}\")\n",
    "print(f\"   Output directory: {config['output_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-conn-desc",
   "metadata": {},
   "source": [
    "### Test DuckDB Connection\n",
    "\n",
    "Verify DuckDB is working and check its capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-conn-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Connect to DuckDB\n",
    "    if config[\"mode\"] == \"memory\":\n",
    "        conn = duckdb.connect(\":memory:\")\n",
    "    else:\n",
    "        conn = duckdb.connect(config[\"database_file\"])\n",
    "\n",
    "    # Configure settings\n",
    "    conn.execute(f\"SET threads TO {config['threads']};\")\n",
    "    conn.execute(f\"SET memory_limit = '{config['memory_limit']}';\")\n",
    "    conn.execute(f\"SET temp_directory = '{config['temp_directory']}';\")\n",
    "\n",
    "    # Check version and settings\n",
    "    version = conn.execute(\"SELECT version();\").fetchone()[0]\n",
    "    print(\"‚úÖ Connected to DuckDB\")\n",
    "    print(f\"   Version: {version}\")\n",
    "\n",
    "    # Check current settings\n",
    "    settings = conn.execute(\"\"\"\n",
    "        SELECT name, value \n",
    "        FROM duckdb_settings() \n",
    "        WHERE name IN ('threads', 'memory_limit', 'temp_directory')\n",
    "        ORDER BY name;\n",
    "    \"\"\").fetchall()\n",
    "\n",
    "    print(\"\\n‚öôÔ∏è  Current Settings:\")\n",
    "    for name, value in settings:\n",
    "        print(f\"   {name}: {value}\")\n",
    "\n",
    "    # Check available extensions\n",
    "    extensions = conn.execute(\"\"\"\n",
    "        SELECT extension_name, loaded \n",
    "        FROM duckdb_extensions() \n",
    "        WHERE extension_name IN ('parquet', 'json', 'httpfs', 'fts')\n",
    "        ORDER BY extension_name;\n",
    "    \"\"\").fetchall()\n",
    "\n",
    "    if extensions:\n",
    "        print(\"\\nüîå Available Extensions:\")\n",
    "        for name, loaded in extensions:\n",
    "            status = \"loaded\" if loaded else \"available\"\n",
    "            print(f\"   {name}: {status}\")\n",
    "\n",
    "    # Simple test query\n",
    "    result = conn.execute(\"SELECT 42 as answer, 'DuckDB' as database;\").fetchone()\n",
    "    print(f\"\\n‚úÖ Test query successful: {result}\")\n",
    "\n",
    "    conn.close()\n",
    "    print(\"\\n‚úÖ Connection test passed!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Connection failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quickstart-header",
   "metadata": {},
   "source": [
    "## 2. Quick Start Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quickstart-desc",
   "metadata": {},
   "source": [
    "### Run TPC-H Power Test\n",
    "\n",
    "Execute a TPC-H power test at scale factor 0.01 (10MB). This runs all 22 TPC-H queries sequentially.\n",
    "\n",
    "**What happens:**\n",
    "1. Generate TPC-H data (customer, orders, lineitem, etc.)\n",
    "2. Create tables in DuckDB\n",
    "3. Load data from generated files\n",
    "4. Execute 22 queries and measure performance\n",
    "\n",
    "**Expected time:** ~30-60 seconds at SF 0.01 on modern hardware\n",
    "\n",
    "**Note**: DuckDB is extremely fast for small datasets. You may see sub-second query times!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quickstart-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure database connection\n",
    "db_cfg = DatabaseConfig(type=\"duckdb\", name=\"duckdb-local\")\n",
    "platform_cfg = {\n",
    "    \"database\": config[\"database_file\"] if config[\"mode\"] == \"persistent\" else \":memory:\",\n",
    "    \"threads\": config[\"threads\"],\n",
    "    \"memory_limit\": config[\"memory_limit\"],\n",
    "}\n",
    "\n",
    "# Configure TPC-H benchmark\n",
    "bench_cfg = BenchmarkConfig(\n",
    "    name=\"tpch\", display_name=\"TPC-H Power Test\", scale_factor=0.01, test_execution_type=\"power\"\n",
    ")\n",
    "\n",
    "# Track start time\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Run complete lifecycle\n",
    "print(\"üöÄ Starting TPC-H power test on DuckDB...\\n\")\n",
    "results = run_benchmark_lifecycle(\n",
    "    benchmark_config=bench_cfg,\n",
    "    database_config=db_cfg,\n",
    "    system_profile=None,\n",
    "    platform_config=platform_cfg,\n",
    "    phases=LifecyclePhases(generate=True, load=True, execute=True),\n",
    ")\n",
    "\n",
    "end_time = datetime.now()\n",
    "total_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "print(\"\\n‚úÖ TPC-H power test completed!\")\n",
    "print(f\"   Benchmark: {results.benchmark_name}\")\n",
    "print(f\"   Total queries: {len(results.query_results)}\")\n",
    "print(f\"   Geometric mean: {results.geometric_mean:.3f}s\")\n",
    "print(f\"   Total execution time: {results.total_execution_time:.2f}s\")\n",
    "print(f\"   Wall clock time: {total_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-desc",
   "metadata": {},
   "source": [
    "### Visualize Results\n",
    "\n",
    "Create a bar chart showing execution time for each query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "if results.query_results:\n",
    "    query_names = [qr.query_name for qr in results.query_results]\n",
    "    execution_times = [qr.execution_time for qr in results.query_results]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    bars = ax.bar(query_names, execution_times, color=\"#FFC220\", alpha=0.8, edgecolor=\"black\")\n",
    "\n",
    "    # Highlight slowest queries\n",
    "    max_time = max(execution_times)\n",
    "    for i, (bar, time) in enumerate(zip(bars, execution_times)):\n",
    "        if time > max_time * 0.7:  # Top 30% slowest\n",
    "            bar.set_color(\"#FF6F00\")  # DuckDB orange accent\n",
    "            # Annotate with time\n",
    "            ax.text(i, time + max_time * 0.02, f\"{time:.3f}s\", ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "\n",
    "    ax.set_xlabel(\"Query\", fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_ylabel(\"Execution Time (seconds)\", fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_title(\"TPC-H Query Performance on DuckDB (SF 0.01)\", fontsize=14, fontweight=\"bold\")\n",
    "    ax.grid(axis=\"y\", alpha=0.3)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nüìä Performance Summary:\")\n",
    "    print(f\"   Fastest query: {query_names[execution_times.index(min(execution_times))]} ({min(execution_times):.3f}s)\")\n",
    "    print(f\"   Slowest query: {query_names[execution_times.index(max(execution_times))]} ({max(execution_times):.3f}s)\")\n",
    "    print(f\"   Median time: {sorted(execution_times)[len(execution_times) // 2]:.3f}s\")\n",
    "\n",
    "    # Calculate queries per second\n",
    "    qps = len(execution_times) / results.total_execution_time\n",
    "    print(f\"   Throughput: {qps:.1f} queries/second\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No query results to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resource-desc",
   "metadata": {},
   "source": [
    "### Monitor Resource Usage\n",
    "\n",
    "Check system resource consumption during the benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resource-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "if psutil:\n",
    "    # Get current resource usage\n",
    "    cpu_percent = psutil.cpu_percent(interval=1)\n",
    "    memory = psutil.virtual_memory()\n",
    "    disk = psutil.disk_usage(\".\")\n",
    "\n",
    "    print(\"üíª Resource Usage:\\n\")\n",
    "    print(f\"CPU Usage: {cpu_percent}%\")\n",
    "    print(f\"Memory: {memory.used / (1024**3):.1f} GB / {memory.total / (1024**3):.1f} GB ({memory.percent}%)\")\n",
    "    print(f\"Disk: {disk.used / (1024**3):.1f} GB / {disk.total / (1024**3):.1f} GB ({disk.percent}%)\")\n",
    "\n",
    "    # Check database file size if persistent\n",
    "    if config[\"mode\"] == \"persistent\" and Path(config[\"database_file\"]).exists():\n",
    "        db_size = Path(config[\"database_file\"]).stat().st_size / (1024**2)  # MB\n",
    "        print(f\"\\nüíæ Database File: {db_size:.1f} MB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Resource monitoring not available (install psutil)\")\n",
    "\n",
    "    # Still check database file size\n",
    "    if config[\"mode\"] == \"persistent\" and Path(config[\"database_file\"]).exists():\n",
    "        db_size = Path(config[\"database_file\"]).stat().st_size / (1024**2)  # MB\n",
    "        print(f\"üíæ Database File: {db_size:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results-desc",
   "metadata": {},
   "source": [
    "### Results Overview\n",
    "\n",
    "Display detailed results including per-query breakdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "results-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Detailed Results:\\n\")\n",
    "print(f\"Benchmark: {results.benchmark_name}\")\n",
    "print(f\"Platform: {results.platform}\")\n",
    "print(f\"Scale Factor: {results.scale_factor}\")\n",
    "print(f\"Test Type: {results.test_execution_type}\")\n",
    "print(f\"Timestamp: {results.start_time}\")\n",
    "print(\"\\nExecution Summary:\")\n",
    "print(f\"  Total queries: {len(results.query_results)}\")\n",
    "print(f\"  Successful: {sum(1 for qr in results.query_results if qr.success)}\")\n",
    "print(f\"  Failed: {sum(1 for qr in results.query_results if not qr.success)}\")\n",
    "print(f\"  Geometric mean: {results.geometric_mean:.3f}s\")\n",
    "print(f\"  Total time: {results.total_execution_time:.2f}s\")\n",
    "\n",
    "if results.data_generation_time:\n",
    "    print(f\"\\nData Generation: {results.data_generation_time:.2f}s\")\n",
    "if results.data_loading_time:\n",
    "    print(f\"Data Loading: {results.data_loading_time:.2f}s\")\n",
    "\n",
    "print(\"\\nüìã Query Breakdown:\")\n",
    "for qr in results.query_results[:5]:  # Show first 5\n",
    "    status = \"‚úÖ\" if qr.success else \"‚ùå\"\n",
    "    print(f\"  {status} {qr.query_name}: {qr.execution_time:.3f}s\")\n",
    "if len(results.query_results) > 5:\n",
    "    print(f\"  ... and {len(results.query_results) - 5} more queries\")\n",
    "\n",
    "print(\"\\nüí° DuckDB Performance Insight:\")\n",
    "print(f\"   DuckDB executed {len(results.query_results)} queries in {results.total_execution_time:.2f}s\")\n",
    "print(f\"   Average query time: {results.total_execution_time / len(results.query_results):.3f}s\")\n",
    "print(\"   This is excellent performance for an embedded database!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-header",
   "metadata": {},
   "source": [
    "## 3. Advanced Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tpcds-desc",
   "metadata": {},
   "source": [
    "### TPC-DS Benchmark\n",
    "\n",
    "Run the more complex TPC-DS benchmark (99 queries) with a smaller subset for faster iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tpcds-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run TPC-DS with query subset\n",
    "tpcds_cfg = BenchmarkConfig(\n",
    "    name=\"tpcds\",\n",
    "    display_name=\"TPC-DS Sample\",\n",
    "    scale_factor=0.01,\n",
    "    test_execution_type=\"power\",\n",
    "    query_numbers=[1, 2, 3, 10, 25],  # Run subset for faster results\n",
    ")\n",
    "\n",
    "print(\"üöÄ Running TPC-DS subset on DuckDB...\\n\")\n",
    "tpcds_results = run_benchmark_lifecycle(\n",
    "    benchmark_config=tpcds_cfg,\n",
    "    database_config=db_cfg,\n",
    "    system_profile=None,\n",
    "    platform_config=platform_cfg,\n",
    "    phases=LifecyclePhases(generate=True, load=True, execute=True),\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ TPC-DS completed: {tpcds_results.geometric_mean:.3f}s geometric mean\")\n",
    "print(f\"   Queries executed: {len(tpcds_results.query_results)}\")\n",
    "print(\"   DuckDB handles TPC-DS's complex queries efficiently!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scale-desc",
   "metadata": {},
   "source": [
    "### Scale Factor Comparison\n",
    "\n",
    "Compare performance across different data sizes to see how DuckDB scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scale-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_results = {}\n",
    "\n",
    "for sf in [0.01, 0.1]:  # Test 10MB and 100MB\n",
    "    print(f\"\\nüöÄ Running TPC-H at scale factor {sf}...\")\n",
    "\n",
    "    sf_cfg = BenchmarkConfig(\n",
    "        name=\"tpch\",\n",
    "        display_name=f\"TPC-H SF {sf}\",\n",
    "        scale_factor=sf,\n",
    "        test_execution_type=\"power\",\n",
    "        query_numbers=list(range(1, 11)),  # First 10 queries only\n",
    "    )\n",
    "\n",
    "    sf_results = run_benchmark_lifecycle(\n",
    "        benchmark_config=sf_cfg,\n",
    "        database_config=db_cfg,\n",
    "        system_profile=None,\n",
    "        platform_config=platform_cfg,\n",
    "        phases=LifecyclePhases(generate=True, load=True, execute=True),\n",
    "    )\n",
    "\n",
    "    scale_results[sf] = sf_results.geometric_mean\n",
    "    print(f\"   Geometric mean: {sf_results.geometric_mean:.3f}s\")\n",
    "\n",
    "# Visualize scaling\n",
    "if len(scale_results) > 1:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sfs = list(scale_results.keys())\n",
    "    times = list(scale_results.values())\n",
    "\n",
    "    ax.plot(sfs, times, marker=\"o\", linewidth=2, markersize=10, color=\"#FFC220\")\n",
    "    ax.set_xlabel(\"Scale Factor\", fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_ylabel(\"Geometric Mean Time (seconds)\", fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_title(\"TPC-H Scaling on DuckDB\", fontsize=14, fontweight=\"bold\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xscale(\"log\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nüìä Scaling Analysis:\")\n",
    "    for i in range(1, len(sfs)):\n",
    "        data_mult = sfs[i] / sfs[i - 1]\n",
    "        time_mult = times[i] / times[i - 1]\n",
    "        efficiency = data_mult / time_mult\n",
    "        print(\n",
    "            f\"   SF {sfs[i - 1]} ‚Üí {sfs[i]}: {data_mult}x data, {time_mult:.2f}x time (efficiency: {efficiency:.2f}x)\"\n",
    "        )\n",
    "\n",
    "    print(\"\\nüí° DuckDB typically shows sub-linear scaling - great for growing datasets!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subset-desc",
   "metadata": {},
   "source": [
    "### Query Subset Selection\n",
    "\n",
    "Run specific queries for targeted testing or CI/CD pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subset-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast smoke test: Run 5 representative queries\n",
    "smoke_test_queries = [1, 3, 6, 10, 14]  # Mix of simple and complex\n",
    "\n",
    "subset_cfg = BenchmarkConfig(\n",
    "    name=\"tpch\",\n",
    "    display_name=\"TPC-H Smoke Test\",\n",
    "    scale_factor=0.01,\n",
    "    test_execution_type=\"power\",\n",
    "    query_numbers=smoke_test_queries,\n",
    ")\n",
    "\n",
    "print(f\"üöÄ Running smoke test with queries: {smoke_test_queries}\\n\")\n",
    "subset_results = run_benchmark_lifecycle(\n",
    "    benchmark_config=subset_cfg,\n",
    "    database_config=db_cfg,\n",
    "    system_profile=None,\n",
    "    platform_config=platform_cfg,\n",
    "    phases=LifecyclePhases(generate=False, load=False, execute=True),  # Reuse data\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Smoke test completed: {subset_results.geometric_mean:.3f}s geometric mean\")\n",
    "print(f\"   Queries: {len(subset_results.query_results)}\")\n",
    "print(f\"   Time saved vs full suite: ~{(1 - len(smoke_test_queries) / 22) * 100:.0f}%\")\n",
    "print(\"\\nüí° Perfect for CI/CD: Run subset tests in seconds, not minutes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "memory-desc",
   "metadata": {},
   "source": [
    "### Memory Tuning\n",
    "\n",
    "Test different memory limits to find optimal configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "memory-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_limits = [\"1GB\", \"2GB\", \"4GB\"]\n",
    "memory_results = {}\n",
    "\n",
    "print(\"üß™ Testing different memory limits...\\n\")\n",
    "\n",
    "for mem_limit in memory_limits:\n",
    "    print(f\"Testing with {mem_limit} memory limit...\")\n",
    "\n",
    "    mem_cfg = platform_cfg.copy()\n",
    "    mem_cfg[\"memory_limit\"] = mem_limit\n",
    "\n",
    "    try:\n",
    "        mem_results_obj = run_benchmark_lifecycle(\n",
    "            benchmark_config=subset_cfg,  # Reuse smoke test config\n",
    "            database_config=db_cfg,\n",
    "            system_profile=None,\n",
    "            platform_config=mem_cfg,\n",
    "            phases=LifecyclePhases(generate=False, load=False, execute=True),\n",
    "        )\n",
    "        memory_results[mem_limit] = mem_results_obj.geometric_mean\n",
    "        print(f\"  ‚úÖ {mem_limit}: {mem_results_obj.geometric_mean:.3f}s\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå {mem_limit}: Failed - {str(e)[:50]}...\\n\")\n",
    "        memory_results[mem_limit] = None\n",
    "\n",
    "if memory_results:\n",
    "    print(\"üìä Memory Limit Comparison:\")\n",
    "    for mem_limit, time in memory_results.items():\n",
    "        if time:\n",
    "            print(f\"   {mem_limit}: {time:.3f}s\")\n",
    "        else:\n",
    "            print(f\"   {mem_limit}: Failed\")\n",
    "\n",
    "    print(\"\\nüí° Lower memory limits may cause disk spilling, increasing query time.\")\n",
    "    print(\"   Recommended: 2-4GB for typical workloads, 8GB+ for large datasets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-desc",
   "metadata": {},
   "source": [
    "### Parallel Execution\n",
    "\n",
    "Test impact of thread count on performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with different thread counts\n",
    "max_threads = os.cpu_count()\n",
    "thread_counts = [1, max_threads // 2, max_threads] if max_threads > 1 else [1]\n",
    "thread_results = {}\n",
    "\n",
    "print(f\"üßµ Testing different thread counts (max: {max_threads})...\\n\")\n",
    "\n",
    "for threads in thread_counts:\n",
    "    print(f\"Testing with {threads} threads...\")\n",
    "\n",
    "    thread_cfg = platform_cfg.copy()\n",
    "    thread_cfg[\"threads\"] = threads\n",
    "\n",
    "    thread_results_obj = run_benchmark_lifecycle(\n",
    "        benchmark_config=subset_cfg,\n",
    "        database_config=db_cfg,\n",
    "        system_profile=None,\n",
    "        platform_config=thread_cfg,\n",
    "        phases=LifecyclePhases(generate=False, load=False, execute=True),\n",
    "    )\n",
    "    thread_results[threads] = thread_results_obj.geometric_mean\n",
    "    print(f\"  ‚úÖ {threads} threads: {thread_results_obj.geometric_mean:.3f}s\\n\")\n",
    "\n",
    "if len(thread_results) > 1:\n",
    "    print(\"üìä Thread Count Comparison:\")\n",
    "    baseline = thread_results[1]\n",
    "    for threads, time in thread_results.items():\n",
    "        speedup = baseline / time if time > 0 else 0\n",
    "        print(f\"   {threads} threads: {time:.3f}s (speedup: {speedup:.2f}x)\")\n",
    "\n",
    "    print(\"\\nüí° DuckDB scales well with more threads for analytical queries.\")\n",
    "    print(f\"   Recommendation: Use all available cores ({max_threads}) for best performance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-desc",
   "metadata": {},
   "source": [
    "### Persistent vs In-Memory Comparison\n",
    "\n",
    "Compare performance between persistent and in-memory modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_results = {}\n",
    "\n",
    "for mode in [\"persistent\", \"memory\"]:\n",
    "    print(f\"\\nüöÄ Testing {mode} mode...\")\n",
    "\n",
    "    mode_cfg = platform_cfg.copy()\n",
    "    mode_cfg[\"database\"] = config[\"database_file\"] if mode == \"persistent\" else \":memory:\"\n",
    "\n",
    "    mode_results_obj = run_benchmark_lifecycle(\n",
    "        benchmark_config=subset_cfg,\n",
    "        database_config=db_cfg,\n",
    "        system_profile=None,\n",
    "        platform_config=mode_cfg,\n",
    "        phases=LifecyclePhases(generate=False, load=True, execute=True),\n",
    "    )\n",
    "    mode_results[mode] = mode_results_obj.geometric_mean\n",
    "    print(f\"  ‚úÖ {mode}: {mode_results_obj.geometric_mean:.3f}s\")\n",
    "\n",
    "print(\"\\nüìä Mode Comparison:\")\n",
    "for mode, time in mode_results.items():\n",
    "    print(f\"   {mode.capitalize()}: {time:.3f}s\")\n",
    "\n",
    "if len(mode_results) == 2:\n",
    "    diff_pct = abs(mode_results[\"persistent\"] - mode_results[\"memory\"]) / mode_results[\"persistent\"] * 100\n",
    "    print(f\"\\n   Difference: {diff_pct:.1f}%\")\n",
    "\n",
    "    print(\"\\nüí° Performance Insights:\")\n",
    "    print(\"   - In-memory is typically slightly faster (no disk I/O)\")\n",
    "    print(\"   - Persistent mode allows data reuse and larger-than-RAM datasets\")\n",
    "    print(\"   - For small datasets, the difference is minimal\")\n",
    "    print(\"   - Choose persistent for production, in-memory for temporary analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export-desc",
   "metadata": {},
   "source": [
    "### Export Results\n",
    "\n",
    "Export benchmark results to various formats for reporting and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to multiple formats\n",
    "try:\n",
    "    exporter = ResultExporter(results)\n",
    "\n",
    "    output_dir = Path(config[\"output_dir\"])\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # Export to JSON\n",
    "    json_path = output_dir / f\"duckdb_tpch_{timestamp}.json\"\n",
    "    exporter.to_json(json_path)\n",
    "    print(f\"‚úÖ Exported JSON: {json_path}\")\n",
    "\n",
    "    # Export to CSV\n",
    "    csv_path = output_dir / f\"duckdb_tpch_{timestamp}.csv\"\n",
    "    exporter.to_csv(csv_path)\n",
    "    print(f\"‚úÖ Exported CSV: {csv_path}\")\n",
    "\n",
    "    # Export to HTML report\n",
    "    html_path = output_dir / f\"duckdb_tpch_{timestamp}.html\"\n",
    "    exporter.to_html(html_path)\n",
    "    print(f\"‚úÖ Exported HTML: {html_path}\")\n",
    "\n",
    "    print(f\"\\nüìÅ All results exported to: {output_dir}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Export failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fileformat-desc",
   "metadata": {},
   "source": [
    "### File Format Comparison\n",
    "\n",
    "DuckDB can read directly from CSV, Parquet, and JSON files. Compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fileformat-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä DuckDB File Format Capabilities\\n\")\n",
    "print(\"DuckDB can query files directly without loading:\")\n",
    "print(\"\\n1. CSV Files:\")\n",
    "print(\"   SELECT * FROM read_csv_auto('data.csv');\")\n",
    "print(\"\\n2. Parquet Files:\")\n",
    "print(\"   SELECT * FROM read_parquet('data.parquet');\")\n",
    "print(\"\\n3. JSON Files:\")\n",
    "print(\"   SELECT * FROM read_json_auto('data.json');\")\n",
    "print(\"\\n4. Multiple Files (Glob patterns):\")\n",
    "print(\"   SELECT * FROM read_parquet('data/*.parquet');\")\n",
    "print(\"\\n5. Remote Files (with httpfs extension):\")\n",
    "print(\"   SELECT * FROM read_parquet('https://example.com/data.parquet');\")\n",
    "\n",
    "print(\"\\nüí° Performance Tips:\")\n",
    "print(\"   - Parquet is fastest (columnar, compressed)\")\n",
    "print(\"   - CSV is most compatible but slower\")\n",
    "print(\"   - Use read_*_auto() for automatic schema detection\")\n",
    "print(\"   - DuckDB can query files in-place without loading!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "platform-header",
   "metadata": {},
   "source": [
    "## 4. Platform-Specific Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "files-desc",
   "metadata": {},
   "source": [
    "### Reading from Files\n",
    "\n",
    "DuckDB's killer feature: Query data files directly without importing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "files-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DuckDB\n",
    "conn = duckdb.connect(\":memory:\")\n",
    "\n",
    "print(\"üìÇ Direct File Querying Examples\\n\")\n",
    "\n",
    "# Example 1: Read CSV\n",
    "print(\"1. CSV Reading:\")\n",
    "print(\n",
    "    \"   \"\n",
    "    + \"\"\"SELECT * FROM read_csv_auto(\n",
    "       'data.csv',\n",
    "       header=True,\n",
    "       delim=',',\n",
    "       auto_detect=True\n",
    "   );\"\"\"\n",
    ")\n",
    "\n",
    "# Example 2: Read Parquet\n",
    "print(\"\\n2. Parquet Reading (Recommended):\")\n",
    "print(\"   SELECT * FROM read_parquet('data.parquet');\")\n",
    "print(\"   -- Or multiple files:\")\n",
    "print(\"   SELECT * FROM read_parquet(['file1.parquet', 'file2.parquet']);\")\n",
    "print(\"   -- Or glob pattern:\")\n",
    "print(\"   SELECT * FROM read_parquet('data/**/*.parquet');\")\n",
    "\n",
    "# Example 3: Create table from file\n",
    "print(\"\\n3. Create Table from File:\")\n",
    "print(\"   CREATE TABLE customers AS SELECT * FROM read_csv_auto('customers.csv');\")\n",
    "\n",
    "# Example 4: Export to Parquet\n",
    "print(\"\\n4. Export Query Results:\")\n",
    "print(\"   COPY (SELECT * FROM customers WHERE country = 'USA')\")\n",
    "print(\"   TO 'usa_customers.parquet' (FORMAT PARQUET);\")\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(\"\\nüí° Why This Matters:\")\n",
    "print(\"   - No ETL required for analysis\")\n",
    "print(\"   - Work with data lakes directly\")\n",
    "print(\"   - Convert between formats easily\")\n",
    "print(\"   - Perfect for data science workflows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pandas-desc",
   "metadata": {},
   "source": [
    "### Pandas Integration\n",
    "\n",
    "DuckDB has seamless integration with pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pandas-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "print(\"üêº DuckDB + Pandas Integration\\n\")\n",
    "\n",
    "# Create sample DataFrame\n",
    "df = pd.DataFrame(\n",
    "    {\"name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"], \"age\": [25, 30, 35, 40], \"salary\": [50000, 60000, 70000, 80000]}\n",
    ")\n",
    "\n",
    "print(\"Sample DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Query DataFrame with SQL\n",
    "result = duckdb.query(\"SELECT name, salary FROM df WHERE age > 30\").to_df()\n",
    "\n",
    "print(\"\\nSQL Query Result:\")\n",
    "print(result)\n",
    "\n",
    "print(\"\\nüìä Integration Examples:\\n\")\n",
    "\n",
    "print(\"1. Query DataFrame:\")\n",
    "print(\"   duckdb.query('SELECT * FROM df WHERE age > 30').to_df()\")\n",
    "\n",
    "print(\"\\n2. Create DuckDB Table from DataFrame:\")\n",
    "print(\"   conn = duckdb.connect()\")\n",
    "print(\"   conn.register('my_table', df)\")\n",
    "print(\"   conn.execute('SELECT * FROM my_table')\")\n",
    "\n",
    "print(\"\\n3. Convert Query Result to DataFrame:\")\n",
    "print(\"   result_df = conn.execute('SELECT * FROM table').df()\")\n",
    "\n",
    "print(\"\\n4. Use Arrow for Zero-Copy Transfer:\")\n",
    "print(\"   arrow_table = conn.execute('SELECT * FROM table').arrow()\")\n",
    "\n",
    "print(\"\\nüí° Performance Tips:\")\n",
    "print(\"   - DuckDB can query pandas DataFrames directly (no copying!)\")\n",
    "print(\"   - Use Arrow for zero-copy data transfer\")\n",
    "print(\"   - DuckDB is often faster than pandas for aggregations\")\n",
    "print(\"   - Perfect for data preprocessing pipelines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensions-desc",
   "metadata": {},
   "source": [
    "### Extensions\n",
    "\n",
    "DuckDB extensions add capabilities like spatial data, full-text search, and remote files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensions-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = duckdb.connect(\":memory:\")\n",
    "\n",
    "print(\"üîå DuckDB Extensions\\n\")\n",
    "\n",
    "# List available extensions\n",
    "extensions = conn.execute(\"\"\"\n",
    "    SELECT extension_name, installed, loaded, description\n",
    "    FROM duckdb_extensions()\n",
    "    WHERE extension_name IN ('httpfs', 'parquet', 'json', 'fts', 'spatial')\n",
    "    ORDER BY extension_name;\n",
    "\"\"\").fetchall()\n",
    "\n",
    "if extensions:\n",
    "    print(\"Available Extensions:\")\n",
    "    for name, installed, loaded, desc in extensions:\n",
    "        status = \"loaded\" if loaded else (\"installed\" if installed else \"available\")\n",
    "        print(f\"\\n{name} ({status}):\")\n",
    "        print(f\"  {desc}\")\n",
    "else:\n",
    "    print(\"No extensions found\")\n",
    "\n",
    "print(\"\\nüì¶ Popular Extensions:\\n\")\n",
    "\n",
    "print(\"1. httpfs - Read remote files:\")\n",
    "print(\"   INSTALL httpfs; LOAD httpfs;\")\n",
    "print(\"   SELECT * FROM read_parquet('https://example.com/data.parquet');\")\n",
    "\n",
    "print(\"\\n2. parquet - Parquet format support:\")\n",
    "print(\"   Usually auto-loaded\")\n",
    "print(\"   SELECT * FROM read_parquet('data.parquet');\")\n",
    "\n",
    "print(\"\\n3. json - JSON support:\")\n",
    "print(\"   INSTALL json; LOAD json;\")\n",
    "print(\"   SELECT * FROM read_json_auto('data.json');\")\n",
    "\n",
    "print(\"\\n4. fts - Full-text search:\")\n",
    "print(\"   INSTALL fts; LOAD fts;\")\n",
    "print(\"   CREATE INDEX idx ON documents USING FTS(content);\")\n",
    "\n",
    "print(\"\\n5. spatial - GIS functionality:\")\n",
    "print(\"   INSTALL spatial; LOAD spatial;\")\n",
    "print(\"   SELECT ST_Distance(point1, point2) FROM locations;\")\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(\"\\nüí° Extension Tips:\")\n",
    "print(\"   - Install once: INSTALL extension_name;\")\n",
    "print(\"   - Load each session: LOAD extension_name;\")\n",
    "print(\"   - Some extensions auto-load when needed\")\n",
    "print(\"   - Check duckdb_extensions() for full list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explain-desc",
   "metadata": {},
   "source": [
    "### EXPLAIN and Query Optimization\n",
    "\n",
    "Use EXPLAIN to understand query execution plans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explain-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = duckdb.connect(config[\"database_file\"] if config[\"mode\"] == \"persistent\" else \":memory:\")\n",
    "\n",
    "print(\"üîç Query Optimization with EXPLAIN\\n\")\n",
    "\n",
    "# Example query\n",
    "query = \"\"\"\n",
    "SELECT l_orderkey, SUM(l_quantity) as total_qty\n",
    "FROM lineitem\n",
    "WHERE l_shipdate >= DATE '1995-01-01'\n",
    "GROUP BY l_orderkey\n",
    "ORDER BY total_qty DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "print(\"Example Query:\")\n",
    "print(query)\n",
    "\n",
    "try:\n",
    "    # Get query plan\n",
    "    plan = conn.execute(f\"EXPLAIN {query}\").fetchall()\n",
    "\n",
    "    print(\"\\nQuery Plan:\")\n",
    "    for row in plan:\n",
    "        print(row[1])  # explain_value column\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è Could not get query plan: {e}\")\n",
    "    print(\"   (This is expected if tables don't exist yet)\")\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(\"\\nüí° EXPLAIN Usage:\\n\")\n",
    "print(\"1. Basic plan: EXPLAIN SELECT ...\")\n",
    "print(\"2. Analyzed plan: EXPLAIN ANALYZE SELECT ...\")\n",
    "print(\"3. Show all details: PRAGMA explain_output = 'all'; EXPLAIN SELECT ...\")\n",
    "\n",
    "print(\"\\nüéØ Optimization Tips:\")\n",
    "print(\"   - Look for 'SEQ_SCAN' - might need indexes\")\n",
    "print(\"   - Check join order - smaller tables first\")\n",
    "print(\"   - Filter early to reduce data scanned\")\n",
    "print(\"   - Use EXPLAIN ANALYZE to see actual timings\")\n",
    "print(\"   - DuckDB is smart - trust the optimizer!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis-header",
   "metadata": {},
   "source": [
    "## 5. Performance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-desc",
   "metadata": {},
   "source": [
    "### Load and Analyze Previous Results\n",
    "\n",
    "Load saved benchmark results for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most recent result file\n",
    "try:\n",
    "    result_files = sorted(Path(config[\"output_dir\"]).glob(\"duckdb_tpch_*.json\"))\n",
    "\n",
    "    if result_files:\n",
    "        latest_file = result_files[-1]\n",
    "        print(f\"üìÇ Loading results from: {latest_file.name}\\n\")\n",
    "\n",
    "        loader = ResultLoader()\n",
    "        loaded_results = loader.load_json(latest_file)\n",
    "\n",
    "        print(f\"‚úÖ Loaded {len(loaded_results.query_results)} query results\")\n",
    "        print(f\"   Benchmark: {loaded_results.benchmark_name}\")\n",
    "        print(f\"   Scale factor: {loaded_results.scale_factor}\")\n",
    "        print(f\"   Geometric mean: {loaded_results.geometric_mean:.3f}s\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No result files found. Run a benchmark first.\")\n",
    "        loaded_results = results  # Use current results\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not load results: {e}\")\n",
    "    loaded_results = results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stats-desc",
   "metadata": {},
   "source": [
    "### Statistical Analysis\n",
    "\n",
    "Calculate detailed statistics on query performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stats-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "if loaded_results.query_results:\n",
    "    times = [qr.execution_time for qr in loaded_results.query_results if qr.success]\n",
    "\n",
    "    if times:\n",
    "        stats = {\n",
    "            \"count\": len(times),\n",
    "            \"mean\": np.mean(times),\n",
    "            \"median\": np.median(times),\n",
    "            \"std\": np.std(times),\n",
    "            \"min\": np.min(times),\n",
    "            \"max\": np.max(times),\n",
    "            \"p25\": np.percentile(times, 25),\n",
    "            \"p75\": np.percentile(times, 75),\n",
    "            \"p95\": np.percentile(times, 95),\n",
    "            \"p99\": np.percentile(times, 99),\n",
    "        }\n",
    "\n",
    "        print(\"üìä Statistical Summary:\\n\")\n",
    "        print(f\"Count:      {stats['count']} queries\")\n",
    "        print(f\"Mean:       {stats['mean']:.3f}s\")\n",
    "        print(f\"Median:     {stats['median']:.3f}s\")\n",
    "        print(f\"Std Dev:    {stats['std']:.3f}s\")\n",
    "        print(f\"Min:        {stats['min']:.3f}s\")\n",
    "        print(f\"Max:        {stats['max']:.3f}s\")\n",
    "        print(\"\\nPercentiles:\")\n",
    "        print(f\"P25:        {stats['p25']:.3f}s\")\n",
    "        print(f\"P75:        {stats['p75']:.3f}s\")\n",
    "        print(f\"P95:        {stats['p95']:.3f}s\")\n",
    "        print(f\"P99:        {stats['p99']:.3f}s\")\n",
    "\n",
    "        # Coefficient of variation\n",
    "        cv = stats[\"std\"] / stats[\"mean\"]\n",
    "        print(f\"\\nCoefficient of Variation: {cv:.2f}\")\n",
    "        if cv < 0.5:\n",
    "            print(\"   ‚úÖ Low variability - consistent performance\")\n",
    "        elif cv < 1.0:\n",
    "            print(\"   ‚ö†Ô∏è  Moderate variability\")\n",
    "        else:\n",
    "            print(\"   ‚ùå High variability - investigate outliers\")\n",
    "\n",
    "        # DuckDB-specific insights\n",
    "        if stats[\"max\"] < 1.0:\n",
    "            print(\"\\nüí° DuckDB Insight: All queries under 1 second - excellent performance!\")\n",
    "        if stats[\"mean\"] < 0.1:\n",
    "            print(\"   Sub-100ms average - DuckDB's vectorized execution shines here!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No successful queries to analyze\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No query results available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-advanced-desc",
   "metadata": {},
   "source": [
    "### Advanced Visualizations\n",
    "\n",
    "Create comprehensive performance visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-advanced-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "if loaded_results.query_results:\n",
    "    times = [qr.execution_time for qr in loaded_results.query_results if qr.success]\n",
    "    query_names = [qr.query_name for qr in loaded_results.query_results if qr.success]\n",
    "\n",
    "    if times:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "        # 1. Histogram with distribution\n",
    "        ax1 = axes[0, 0]\n",
    "        ax1.hist(times, bins=20, color=\"#FFC220\", alpha=0.7, edgecolor=\"black\")\n",
    "        ax1.axvline(np.mean(times), color=\"#FF6F00\", linestyle=\"--\", linewidth=2, label=f\"Mean: {np.mean(times):.3f}s\")\n",
    "        ax1.axvline(\n",
    "            np.median(times), color=\"green\", linestyle=\"--\", linewidth=2, label=f\"Median: {np.median(times):.3f}s\"\n",
    "        )\n",
    "        ax1.set_xlabel(\"Execution Time (seconds)\", fontweight=\"bold\")\n",
    "        ax1.set_ylabel(\"Frequency\", fontweight=\"bold\")\n",
    "        ax1.set_title(\"Query Execution Time Distribution\", fontweight=\"bold\")\n",
    "        ax1.legend()\n",
    "        ax1.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "        # 2. Box plot\n",
    "        ax2 = axes[0, 1]\n",
    "        box = ax2.boxplot([times], vert=True, patch_artist=True, widths=0.5)\n",
    "        box[\"boxes\"][0].set_facecolor(\"#FFC220\")\n",
    "        box[\"boxes\"][0].set_alpha(0.7)\n",
    "        ax2.set_ylabel(\"Execution Time (seconds)\", fontweight=\"bold\")\n",
    "        ax2.set_title(\"Query Performance Box Plot\", fontweight=\"bold\")\n",
    "        ax2.set_xticklabels([\"All Queries\"])\n",
    "        ax2.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "        # 3. Sorted bar chart (top 10 slowest)\n",
    "        ax3 = axes[1, 0]\n",
    "        sorted_indices = np.argsort(times)[-10:]\n",
    "        sorted_times = [times[i] for i in sorted_indices]\n",
    "        sorted_names = [query_names[i] for i in sorted_indices]\n",
    "\n",
    "        bars = ax3.barh(sorted_names, sorted_times, color=\"#FFC220\", alpha=0.8, edgecolor=\"black\")\n",
    "        ax3.set_xlabel(\"Execution Time (seconds)\", fontweight=\"bold\")\n",
    "        ax3.set_title(\"Top 10 Slowest Queries\", fontweight=\"bold\")\n",
    "        ax3.grid(axis=\"x\", alpha=0.3)\n",
    "\n",
    "        # 4. Cumulative performance (Pareto)\n",
    "        ax4 = axes[1, 1]\n",
    "        sorted_all_indices = np.argsort(times)[::-1]\n",
    "        sorted_all_times = [times[i] for i in sorted_all_indices]\n",
    "        cumulative = np.cumsum(sorted_all_times)\n",
    "        cumulative_pct = (cumulative / cumulative[-1]) * 100\n",
    "\n",
    "        ax4.plot(range(len(cumulative_pct)), cumulative_pct, marker=\"o\", color=\"#FFC220\", linewidth=2)\n",
    "        ax4.axhline(80, color=\"#FF6F00\", linestyle=\"--\", linewidth=2, label=\"80% of total time\")\n",
    "        ax4.set_xlabel(\"Number of Queries (sorted by time)\", fontweight=\"bold\")\n",
    "        ax4.set_ylabel(\"Cumulative % of Total Time\", fontweight=\"bold\")\n",
    "        ax4.set_title(\"Cumulative Performance (Pareto Analysis)\", fontweight=\"bold\")\n",
    "        ax4.legend()\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "\n",
    "        # Find how many queries account for 80% of time\n",
    "        queries_80pct = np.argmax(cumulative_pct >= 80) + 1\n",
    "        ax4.axvline(\n",
    "            queries_80pct, color=\"green\", linestyle=\"--\", linewidth=2, label=f\"{queries_80pct} queries = 80% time\"\n",
    "        )\n",
    "        ax4.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        print(\n",
    "            f\"\\nüí° Insight: {queries_80pct} queries ({queries_80pct / len(times) * 100:.0f}%) account for 80% of total execution time\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No successful queries to visualize\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No query results available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "memory-track-desc",
   "metadata": {},
   "source": [
    "### Memory Usage Tracking\n",
    "\n",
    "Monitor memory consumption during benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "memory-track-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "if psutil:\n",
    "    process = psutil.Process()\n",
    "\n",
    "    print(\"üíæ Memory Usage Analysis\\n\")\n",
    "\n",
    "    # Get process memory info\n",
    "    mem_info = process.memory_info()\n",
    "    mem_mb = mem_info.rss / (1024**2)\n",
    "\n",
    "    print(f\"Current Process Memory: {mem_mb:.1f} MB\")\n",
    "\n",
    "    # System memory\n",
    "    sys_mem = psutil.virtual_memory()\n",
    "    print(f\"System Memory Usage: {sys_mem.percent}%\")\n",
    "    print(f\"Available: {sys_mem.available / (1024**3):.1f} GB\")\n",
    "\n",
    "    # Database file size\n",
    "    if config[\"mode\"] == \"persistent\" and Path(config[\"database_file\"]).exists():\n",
    "        db_size = Path(config[\"database_file\"]).stat().st_size / (1024**2)\n",
    "        print(f\"\\nDatabase File: {db_size:.1f} MB\")\n",
    "\n",
    "    print(\"\\nüí° Memory Optimization Tips:\")\n",
    "    print(\"   - Use persistent mode for large datasets\")\n",
    "    print(\"   - Adjust memory_limit setting if needed\")\n",
    "    print(\"   - DuckDB will spill to disk if memory is insufficient\")\n",
    "    print(\"   - Monitor temp_directory disk usage for spilling\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Memory tracking not available (install psutil)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "profiling-desc",
   "metadata": {},
   "source": [
    "### Performance Profiling\n",
    "\n",
    "Use DuckDB's built-in profiling to understand query performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "profiling-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî¨ DuckDB Performance Profiling\\n\")\n",
    "print(\"DuckDB provides built-in profiling:\")\n",
    "print(\"\\n1. Enable profiling:\")\n",
    "print(\"   PRAGMA enable_profiling;\")\n",
    "print(\"   PRAGMA profiling_output = 'profile_output.json';\")\n",
    "print(\"\\n2. Run your queries...\")\n",
    "print(\"\\n3. View profile:\")\n",
    "print(\"   PRAGMA last_profile_query;\")\n",
    "\n",
    "print(\"\\nüìä What Profiling Shows:\")\n",
    "print(\"   - Time spent in each operator\")\n",
    "print(\"   - Number of rows processed\")\n",
    "print(\"   - Memory usage per operator\")\n",
    "print(\"   - Bottlenecks in query execution\")\n",
    "\n",
    "print(\"\\nüí° Quick Profiling Tips:\")\n",
    "print(\"   - Focus on operators taking >10% of time\")\n",
    "print(\"   - Look for unexpected full table scans\")\n",
    "print(\"   - Check if sorts/aggregations are slow\")\n",
    "print(\"   - Consider adding indexes for frequent lookups\")\n",
    "print(\"   - DuckDB automatically optimizes most queries!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "troubleshooting-header",
   "metadata": {},
   "source": [
    "## 6. Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diag-desc",
   "metadata": {},
   "source": [
    "### Diagnostics Function\n",
    "\n",
    "Comprehensive diagnostic tool for troubleshooting DuckDB issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diag-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnose_duckdb():\n",
    "    \"\"\"Diagnose DuckDB setup and configuration\"\"\"\n",
    "    print(\"üîç DuckDB Diagnostic\\n\")\n",
    "\n",
    "    # Check 1: DuckDB import\n",
    "    print(\"1. Checking DuckDB installation...\")\n",
    "    try:\n",
    "        import duckdb\n",
    "\n",
    "        print(f\"   ‚úÖ DuckDB {duckdb.__version__} installed\")\n",
    "    except ImportError:\n",
    "        print(\"   ‚ùå DuckDB not installed\")\n",
    "        print(\"   Action: pip install duckdb\")\n",
    "        return False\n",
    "\n",
    "    # Check 2: Test connection\n",
    "    print(\"\\n2. Testing connection...\")\n",
    "    try:\n",
    "        conn = duckdb.connect(\":memory:\")\n",
    "        result = conn.execute(\"SELECT 42 as answer;\").fetchone()\n",
    "        conn.close()\n",
    "        print(f\"   ‚úÖ Connection successful: {result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Connection failed: {e}\")\n",
    "        return False\n",
    "\n",
    "    # Check 3: System resources\n",
    "    print(\"\\n3. Checking system resources...\")\n",
    "    if psutil:\n",
    "        mem = psutil.virtual_memory()\n",
    "        cpu = psutil.cpu_count()\n",
    "        print(f\"   ‚úÖ CPU cores: {cpu}\")\n",
    "        print(f\"   ‚úÖ RAM: {mem.total / (1024**3):.1f} GB ({mem.available / (1024**3):.1f} GB available)\")\n",
    "\n",
    "        if mem.available < 1024**3:  # Less than 1GB available\n",
    "            print(\"   ‚ö†Ô∏è  Low memory - reduce memory_limit setting\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  psutil not available - install for resource monitoring\")\n",
    "\n",
    "    # Check 4: Database file (if persistent)\n",
    "    print(\"\\n4. Checking database configuration...\")\n",
    "    if config[\"mode\"] == \"persistent\":\n",
    "        db_path = Path(config[\"database_file\"])\n",
    "        if db_path.exists():\n",
    "            size_mb = db_path.stat().st_size / (1024**2)\n",
    "            print(f\"   ‚úÖ Database file exists: {size_mb:.1f} MB\")\n",
    "        else:\n",
    "            print(f\"   ‚ÑπÔ∏è  Database file will be created: {db_path}\")\n",
    "\n",
    "        # Check parent directory is writable\n",
    "        parent = db_path.parent\n",
    "        if parent.exists() and os.access(parent, os.W_OK):\n",
    "            print(f\"   ‚úÖ Directory writable: {parent}\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå Directory not writable: {parent}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"   ‚ÑπÔ∏è  Using in-memory mode\")\n",
    "\n",
    "    # Check 5: Extensions\n",
    "    print(\"\\n5. Checking extensions...\")\n",
    "    try:\n",
    "        conn = duckdb.connect(\":memory:\")\n",
    "        exts = conn.execute(\"\"\"\n",
    "            SELECT extension_name, installed\n",
    "            FROM duckdb_extensions()\n",
    "            WHERE extension_name IN ('parquet', 'json', 'httpfs')\n",
    "        \"\"\").fetchall()\n",
    "        conn.close()\n",
    "\n",
    "        for name, installed in exts:\n",
    "            status = \"installed\" if installed else \"available\"\n",
    "            print(f\"   {name}: {status}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Could not check extensions: {e}\")\n",
    "\n",
    "    print(\"\\n‚úÖ All diagnostics passed!\")\n",
    "    print(\"\\nüìö Additional Resources:\")\n",
    "    print(\"   - DuckDB Documentation: https://duckdb.org/docs/\")\n",
    "    print(\"   - GitHub Issues: https://github.com/duckdb/duckdb/issues\")\n",
    "    print(\"   - Discord Community: https://discord.duckdb.org/\")\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "# Run diagnostics\n",
    "diagnose_duckdb()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-issues-desc",
   "metadata": {},
   "source": [
    "### Common Issues and Solutions\n",
    "\n",
    "**1. Out of Memory Error**\n",
    "```\n",
    "Error: Out of Memory\n",
    "```\n",
    "**Solution:**\n",
    "- Reduce `memory_limit` setting: `SET memory_limit = '2GB';`\n",
    "- Use persistent mode instead of in-memory\n",
    "- Ensure `temp_directory` has sufficient disk space for spilling\n",
    "- Process data in smaller batches\n",
    "\n",
    "**2. File Lock Error (Persistent Mode)**\n",
    "```\n",
    "Error: Could not set lock on file\n",
    "```\n",
    "**Solution:**\n",
    "- Close all connections to the database\n",
    "- Check no other processes are using the .duckdb file\n",
    "- Use `conn.close()` to properly close connections\n",
    "- Delete .duckdb.wal file if safe\n",
    "\n",
    "**3. Slow Query Performance**\n",
    "**Solution:**\n",
    "- Increase thread count: `SET threads TO 8;`\n",
    "- Increase memory limit if available\n",
    "- Use EXPLAIN ANALYZE to find bottlenecks\n",
    "- Consider creating indexes for frequent lookups\n",
    "- Use Parquet files instead of CSV for better performance\n",
    "\n",
    "**4. Extension Not Found**\n",
    "```\n",
    "Error: Extension \"httpfs\" not found\n",
    "```\n",
    "**Solution:**\n",
    "```sql\n",
    "INSTALL httpfs;\n",
    "LOAD httpfs;\n",
    "```\n",
    "\n",
    "**5. File Not Found (Reading Data)**\n",
    "```\n",
    "Error: Could not open file\n",
    "```\n",
    "**Solution:**\n",
    "- Use absolute paths: `/full/path/to/file.csv`\n",
    "- Check file permissions\n",
    "- Verify file exists: `Path('file.csv').exists()`\n",
    "- Use forward slashes even on Windows: `data/file.csv`\n",
    "\n",
    "**6. Catalog Error (Table Not Found)**\n",
    "```\n",
    "Error: Table with name \"mytable\" does not exist\n",
    "```\n",
    "**Solution:**\n",
    "- In-memory databases don't persist between sessions\n",
    "- Use persistent mode for data reuse\n",
    "- Check table name spelling (case-sensitive)\n",
    "- Verify connection to correct database file\n",
    "\n",
    "**7. Import/Export Errors**\n",
    "**Solution:**\n",
    "- Use read_csv_auto() for automatic type detection\n",
    "- Specify delimiter explicitly: `delim=','`\n",
    "- Handle null values: `null_padding=True`\n",
    "- Check file encoding: `encoding='UTF-8'`\n",
    "\n",
    "**8. Version Compatibility**\n",
    "**Solution:**\n",
    "- Update DuckDB: `pip install -U duckdb`\n",
    "- Check version: `duckdb.__version__`\n",
    "- Some features require newer versions\n",
    "- Clear cached .duckdb files after upgrades\n",
    "\n",
    "**Need More Help?**\n",
    "- DuckDB Documentation: https://duckdb.org/docs/\n",
    "- GitHub Issues: https://github.com/duckdb/duckdb/issues\n",
    "- Discord Community: https://discord.duckdb.org/\n",
    "- Stack Overflow: https://stackoverflow.com/questions/tagged/duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tuning-desc",
   "metadata": {},
   "source": [
    "### Performance Tuning Guide\n",
    "\n",
    "**Configuration Settings:**\n",
    "```sql\n",
    "-- Use all CPU cores\n",
    "SET threads TO 8;\n",
    "\n",
    "-- Set memory limit (adjust for your system)\n",
    "SET memory_limit = '4GB';\n",
    "\n",
    "-- Configure temp directory for spilling\n",
    "SET temp_directory = '/path/to/temp';\n",
    "\n",
    "-- Disable optimizer for debugging (not recommended)\n",
    "SET disabled_optimizers = 'join_order';\n",
    "```\n",
    "\n",
    "**Data Loading Best Practices:**\n",
    "1. **Use Parquet files** - Faster than CSV by 10-100x\n",
    "2. **Parallel loading** - DuckDB loads multiple files in parallel\n",
    "3. **Compression** - Parquet with Snappy or ZSTD compression\n",
    "4. **Partition files** - Split large files into 100MB-1GB chunks\n",
    "\n",
    "**Query Optimization:**\n",
    "1. **Filter early** - WHERE clauses before joins\n",
    "2. **Select only needed columns** - Avoid SELECT *\n",
    "3. **Use appropriate joins** - Let optimizer choose join order\n",
    "4. **Aggregate efficiently** - GROUP BY early if possible\n",
    "5. **Trust the optimizer** - DuckDB is very good at optimization\n",
    "\n",
    "**Memory Management:**\n",
    "- Start with 50% of available RAM: `memory_limit = '4GB'`\n",
    "- Increase if queries are fast and memory available\n",
    "- Decrease if getting OOM errors\n",
    "- DuckDB will spill to disk if needed (check temp_directory)\n",
    "\n",
    "**When to Use Each Mode:**\n",
    "\n",
    "**In-Memory Mode:**\n",
    "- ‚úÖ Temporary analysis\n",
    "- ‚úÖ Small datasets (<1GB)\n",
    "- ‚úÖ Maximum speed\n",
    "- ‚ùå No data persistence\n",
    "- ‚ùå Limited by RAM\n",
    "\n",
    "**Persistent Mode:**\n",
    "- ‚úÖ Data reuse\n",
    "- ‚úÖ Larger-than-RAM datasets\n",
    "- ‚úÖ Production workloads\n",
    "- ‚úÖ Crash recovery\n",
    "- ‚ùå Slightly slower (minimal difference)\n",
    "\n",
    "**Benchmarking Tips:**\n",
    "1. **Warm-up run** - First execution may be slower (compilation)\n",
    "2. **Multiple runs** - Average 3-5 runs for stability\n",
    "3. **Clear caches** - Close and reopen connection between tests\n",
    "4. **Monitor resources** - Check CPU, memory, and disk usage\n",
    "5. **Compare apples-to-apples** - Same hardware, same data, same queries\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "**Try these next:**\n",
    "1. Run with larger scale factors (1.0, 10, 100)\n",
    "2. Test with your own datasets (CSV, Parquet)\n",
    "3. Compare DuckDB vs other databases\n",
    "4. Integrate with your Python data pipeline\n",
    "5. Explore DuckDB extensions (spatial, full-text search)\n",
    "\n",
    "**Related notebooks:**\n",
    "- `sqlite_benchmarking.ipynb` - Compare with SQLite\n",
    "- `platform_comparison.ipynb` - Compare cloud vs local\n",
    "- `visualization_examples.ipynb` - Advanced plotting\n",
    "\n",
    "**Resources:**\n",
    "- BenchBox Documentation: https://github.com/joeharris76/benchbox\n",
    "- DuckDB Documentation: https://duckdb.org/docs/\n",
    "- TPC Benchmarks: http://www.tpc.org/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
