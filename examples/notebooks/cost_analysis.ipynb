{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BenchBox Cost Analysis\n",
    "\n",
    "This notebook provides comprehensive **cost tracking, estimation, and optimization** tools for cloud data warehouse benchmarking. Understanding the cost implications of your platform choices and workload patterns is critical for making informed decisions.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- **Track actual costs** from benchmark runs on cloud platforms\n",
    "- **Estimate costs** for different scale factors and workloads\n",
    "- **Project costs** for production-scale usage\n",
    "- **Optimize spending** with platform-specific recommendations\n",
    "- **Set budget alerts** and cost thresholds\n",
    "- **Calculate ROI** for platform migrations\n",
    "\n",
    "## Supported Platforms\n",
    "\n",
    "- **Databricks**: DBU consumption + compute costs\n",
    "- **BigQuery**: On-demand vs reserved slots, per-TB pricing\n",
    "- **Snowflake**: Credit consumption, warehouse sizing, storage\n",
    "- **Redshift**: Node hours, concurrency scaling, storage\n",
    "- **Local**: DuckDB and SQLite (infrastructure costs only)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Run benchmarks on cloud platforms using the platform-specific notebooks first.\n",
    "\n",
    "## Expected Runtime\n",
    "\n",
    "Cost analysis runs quickly on existing results:\n",
    "- Data loading: **10-30 seconds**\n",
    "- Analysis and projections: **30-60 seconds**\n",
    "- Complete notebook: **1-2 minutes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install BenchBox if not already installed\n",
    "# !pip install benchbox\n",
    "\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from benchbox import __version__\n",
    "\n",
    "print(f\"BenchBox version: {__version__}\")\n",
    "print(f\"Analysis date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost Configuration\n",
    "# **IMPORTANT**: Update these with your actual pricing\n",
    "\n",
    "config = {\n",
    "    # Results directories\n",
    "    \"results_dirs\": {\n",
    "        \"databricks\": \"./benchmark_results/databricks\",\n",
    "        \"bigquery\": \"./benchmark_results/bigquery\",\n",
    "        \"snowflake\": \"./benchmark_results/snowflake\",\n",
    "        \"redshift\": \"./benchmark_results/redshift\",\n",
    "    },\n",
    "    # Databricks pricing\n",
    "    \"databricks\": {\n",
    "        \"dbu_rate\": 8.0,  # DBUs consumed per hour by cluster\n",
    "        \"dbu_cost\": 0.40,  # Cost per DBU (Standard tier)\n",
    "        \"compute_cost\": 0.15,  # EC2/compute cost per hour\n",
    "        \"storage_per_tb_month\": 0.20,  # Delta Lake storage\n",
    "    },\n",
    "    # BigQuery pricing\n",
    "    \"bigquery\": {\n",
    "        \"on_demand_per_tb\": 5.00,  # On-demand per TB processed\n",
    "        \"slots_per_hour\": 0.04,  # Flat-rate slots (per 100 slots)\n",
    "        \"active_storage_per_tb\": 0.02,  # Active storage per TB/month\n",
    "        \"long_term_storage_per_tb\": 0.01,  # >90 days inactive\n",
    "    },\n",
    "    # Snowflake pricing\n",
    "    \"snowflake\": {\n",
    "        \"credit_cost\": 2.00,  # Enterprise edition\n",
    "        \"storage_per_tb_month\": 0.023,  # Storage cost\n",
    "        \"warehouse_credits\": {  # Credits per hour by size\n",
    "            \"X-Small\": 1,\n",
    "            \"Small\": 2,\n",
    "            \"Medium\": 4,\n",
    "            \"Large\": 8,\n",
    "            \"X-Large\": 16,\n",
    "            \"2X-Large\": 32,\n",
    "            \"3X-Large\": 64,\n",
    "            \"4X-Large\": 128,\n",
    "        },\n",
    "    },\n",
    "    # Redshift pricing\n",
    "    \"redshift\": {\n",
    "        \"node_types\": {\n",
    "            \"ra3.xlplus\": 1.086,  # On-demand per node per hour\n",
    "            \"ra3.4xlarge\": 3.26,\n",
    "            \"ra3.16xlarge\": 13.04,\n",
    "            \"dc2.large\": 0.25,\n",
    "            \"dc2.8xlarge\": 4.80,\n",
    "        },\n",
    "        \"storage_per_tb_month\": 0.024,  # RA3 managed storage\n",
    "        \"concurrency_scaling_per_second\": 0.000003,\n",
    "    },\n",
    "    # Budget settings\n",
    "    \"budget\": {\n",
    "        \"monthly_limit\": 1000.00,  # Total monthly budget (USD)\n",
    "        \"daily_limit\": 50.00,  # Daily spending limit\n",
    "        \"alert_threshold\": 0.80,  # Alert at 80% of budget\n",
    "    },\n",
    "    # Output directory\n",
    "    \"output_dir\": \"./cost_analysis\",\n",
    "}\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(config[\"output_dir\"], exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Configuration loaded\")\n",
    "print(f\"üí∞ Monthly budget: ${config['budget']['monthly_limit']:.2f}\")\n",
    "print(f\"‚ö†Ô∏è  Alert threshold: {config['budget']['alert_threshold'] * 100:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Benchmark Results with Cost Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results_with_metadata(platform: str, results_dir: str) -> List[Dict]:\n",
    "    \"\"\"Load all benchmark results for a platform with timestamps.\n",
    "\n",
    "    Returns:\n",
    "        List of result dictionaries with metadata\n",
    "    \"\"\"\n",
    "    results_path = Path(results_dir)\n",
    "\n",
    "    if not results_path.exists():\n",
    "        print(f\"‚ö†Ô∏è  No results found for {platform}\")\n",
    "        return []\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    for json_file in sorted(results_path.glob(\"*.json\")):\n",
    "        try:\n",
    "            with open(json_file) as f:\n",
    "                result = json.load(f)\n",
    "\n",
    "            # Add file metadata\n",
    "            result[\"_file\"] = json_file.name\n",
    "            result[\"_file_time\"] = datetime.fromtimestamp(json_file.stat().st_mtime)\n",
    "            result[\"_platform\"] = platform\n",
    "\n",
    "            all_results.append(result)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Error loading {json_file.name}: {e}\")\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "# Load all results\n",
    "all_platform_results = {}\n",
    "\n",
    "for platform, results_dir in config[\"results_dirs\"].items():\n",
    "    results = load_results_with_metadata(platform, results_dir)\n",
    "    if results:\n",
    "        all_platform_results[platform] = results\n",
    "        print(f\"‚úÖ {platform.capitalize()}: {len(results)} benchmark runs\")\n",
    "\n",
    "total_runs = sum(len(r) for r in all_platform_results.values())\n",
    "print(f\"\\nüìä Total benchmark runs: {total_runs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate Costs per Benchmark Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_databricks_cost(result: Dict, pricing: Dict) -> Dict:\n",
    "    \"\"\"Calculate Databricks cost breakdown.\"\"\"\n",
    "    total_time_ms = sum(\n",
    "        qr.get(\"execution_time_ms\", 0) for qr in result.get(\"query_results\", []) if qr.get(\"success\", False)\n",
    "    )\n",
    "    total_hours = total_time_ms / (1000 * 60 * 60)\n",
    "\n",
    "    dbu_consumption = total_hours * pricing[\"dbu_rate\"]\n",
    "    dbu_cost = dbu_consumption * pricing[\"dbu_cost\"]\n",
    "    compute_cost = total_hours * pricing[\"compute_cost\"]\n",
    "    total_cost = dbu_cost + compute_cost\n",
    "\n",
    "    return {\n",
    "        \"total_cost\": total_cost,\n",
    "        \"dbu_cost\": dbu_cost,\n",
    "        \"compute_cost\": compute_cost,\n",
    "        \"dbu_consumption\": dbu_consumption,\n",
    "        \"total_hours\": total_hours,\n",
    "    }\n",
    "\n",
    "\n",
    "def calculate_bigquery_cost(result: Dict, pricing: Dict) -> Dict:\n",
    "    \"\"\"Calculate BigQuery cost (requires bytes processed from results).\"\"\"\n",
    "    # Try to get actual bytes processed from results\n",
    "    total_bytes = result.get(\"total_bytes_processed\", 0)\n",
    "\n",
    "    if total_bytes == 0:\n",
    "        # Estimate based on scale factor (rough approximation)\n",
    "        scale = result.get(\"scale_factor\", 0.1)\n",
    "        # TPC-H SF 1 ‚âà 1GB, typical query scans ~20% of data\n",
    "        total_bytes = scale * 1e9 * 0.2 * len(result.get(\"query_results\", []))\n",
    "\n",
    "    tb_processed = total_bytes / 1e12\n",
    "    query_cost = tb_processed * pricing[\"on_demand_per_tb\"]\n",
    "\n",
    "    return {\n",
    "        \"total_cost\": query_cost,\n",
    "        \"query_cost\": query_cost,\n",
    "        \"tb_processed\": tb_processed,\n",
    "        \"bytes_processed\": total_bytes,\n",
    "    }\n",
    "\n",
    "\n",
    "def calculate_snowflake_cost(result: Dict, pricing: Dict) -> Dict:\n",
    "    \"\"\"Calculate Snowflake cost.\"\"\"\n",
    "    total_time_ms = sum(\n",
    "        qr.get(\"execution_time_ms\", 0) for qr in result.get(\"query_results\", []) if qr.get(\"success\", False)\n",
    "    )\n",
    "    total_hours = total_time_ms / (1000 * 60 * 60)\n",
    "\n",
    "    # Get warehouse size from result or assume X-Small\n",
    "    warehouse_size = result.get(\"warehouse_size\", \"X-Small\")\n",
    "    credits_per_hour = pricing[\"warehouse_credits\"].get(warehouse_size, 1)\n",
    "\n",
    "    credits_consumed = total_hours * credits_per_hour\n",
    "    compute_cost = credits_consumed * pricing[\"credit_cost\"]\n",
    "\n",
    "    return {\n",
    "        \"total_cost\": compute_cost,\n",
    "        \"compute_cost\": compute_cost,\n",
    "        \"credits_consumed\": credits_consumed,\n",
    "        \"total_hours\": total_hours,\n",
    "        \"warehouse_size\": warehouse_size,\n",
    "    }\n",
    "\n",
    "\n",
    "def calculate_redshift_cost(result: Dict, pricing: Dict) -> Dict:\n",
    "    \"\"\"Calculate Redshift cost.\"\"\"\n",
    "    total_time_ms = sum(\n",
    "        qr.get(\"execution_time_ms\", 0) for qr in result.get(\"query_results\", []) if qr.get(\"success\", False)\n",
    "    )\n",
    "    total_hours = total_time_ms / (1000 * 60 * 60)\n",
    "\n",
    "    # Get node type and count from result or use defaults\n",
    "    node_type = result.get(\"node_type\", \"ra3.xlplus\")\n",
    "    node_count = result.get(\"node_count\", 2)\n",
    "    node_cost_per_hour = pricing[\"node_types\"].get(node_type, 1.0)\n",
    "\n",
    "    compute_cost = total_hours * node_count * node_cost_per_hour\n",
    "\n",
    "    return {\n",
    "        \"total_cost\": compute_cost,\n",
    "        \"compute_cost\": compute_cost,\n",
    "        \"total_hours\": total_hours,\n",
    "        \"node_type\": node_type,\n",
    "        \"node_count\": node_count,\n",
    "    }\n",
    "\n",
    "\n",
    "# Calculate costs for all results\n",
    "cost_calculators = {\n",
    "    \"databricks\": calculate_databricks_cost,\n",
    "    \"bigquery\": calculate_bigquery_cost,\n",
    "    \"snowflake\": calculate_snowflake_cost,\n",
    "    \"redshift\": calculate_redshift_cost,\n",
    "}\n",
    "\n",
    "cost_records = []\n",
    "\n",
    "for platform, results in all_platform_results.items():\n",
    "    calculator = cost_calculators.get(platform)\n",
    "    if not calculator:\n",
    "        continue\n",
    "\n",
    "    platform_config = config.get(platform, {})\n",
    "\n",
    "    for result in results:\n",
    "        try:\n",
    "            cost_data = calculator(result, platform_config)\n",
    "\n",
    "            record = {\n",
    "                \"platform\": platform,\n",
    "                \"timestamp\": result[\"_file_time\"],\n",
    "                \"benchmark\": result.get(\"benchmark_name\", \"unknown\"),\n",
    "                \"scale_factor\": result.get(\"scale_factor\", 0),\n",
    "                \"num_queries\": len(result.get(\"query_results\", [])),\n",
    "                \"successful_queries\": sum(1 for qr in result.get(\"query_results\", []) if qr.get(\"success\", False)),\n",
    "                **cost_data,\n",
    "            }\n",
    "            cost_records.append(record)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Error calculating cost for {platform}: {e}\")\n",
    "\n",
    "df_costs = pd.DataFrame(cost_records)\n",
    "\n",
    "if len(df_costs) > 0:\n",
    "    print(f\"üìä Calculated costs for {len(df_costs)} benchmark runs\")\n",
    "    print(\"\\nTotal spending by platform:\")\n",
    "    print(df_costs.groupby(\"platform\")[\"total_cost\"].sum().apply(lambda x: f\"${x:.2f}\"))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No cost data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cost Breakdown Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_costs) > 0:\n",
    "    # Summary statistics\n",
    "    cost_summary = (\n",
    "        df_costs.groupby(\"platform\")\n",
    "        .agg(\n",
    "            {\n",
    "                \"total_cost\": [\"sum\", \"mean\", \"median\", \"min\", \"max\"],\n",
    "                \"num_queries\": \"sum\",\n",
    "                \"successful_queries\": \"sum\",\n",
    "            }\n",
    "        )\n",
    "        .round(4)\n",
    "    )\n",
    "\n",
    "    cost_summary.columns = [\"_\".join(col).strip() for col in cost_summary.columns.values]\n",
    "\n",
    "    # Calculate cost per query\n",
    "    cost_summary[\"cost_per_query\"] = (cost_summary[\"total_cost_sum\"] / cost_summary[\"successful_queries_sum\"]).round(6)\n",
    "\n",
    "    print(\"üí∞ Cost Summary by Platform\\n\")\n",
    "    print(cost_summary)\n",
    "\n",
    "    print(\"\\nüìä Cost Metrics:\")\n",
    "    for platform in cost_summary.index:\n",
    "        total = cost_summary.loc[platform, \"total_cost_sum\"]\n",
    "        per_query = cost_summary.loc[platform, \"cost_per_query\"]\n",
    "        print(f\"  {platform.capitalize()}: ${total:.2f} total, ${per_query:.6f} per query\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Insufficient data for cost analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Cost breakdown\n",
    "if len(df_costs) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Plot 1: Total cost by platform\n",
    "    ax1 = axes[0]\n",
    "    platform_totals = df_costs.groupby(\"platform\")[\"total_cost\"].sum().sort_values(ascending=False)\n",
    "\n",
    "    colors = [\"#4285F4\", \"#FF3621\", \"#29B5E8\", \"#CC0000\"][: len(platform_totals)]\n",
    "    bars = ax1.bar(range(len(platform_totals)), platform_totals.values, color=colors, alpha=0.8)\n",
    "    ax1.set_xticks(range(len(platform_totals)))\n",
    "    ax1.set_xticklabels([p.capitalize() for p in platform_totals.index], rotation=45, ha=\"right\")\n",
    "    ax1.set_ylabel(\"Total Cost (USD)\", fontsize=11)\n",
    "    ax1.set_title(\"Total Benchmark Costs by Platform\", fontsize=12, fontweight=\"bold\")\n",
    "    ax1.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "    # Add value labels\n",
    "    for bar, value in zip(bars, platform_totals.values):\n",
    "        ax1.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            value + max(platform_totals.values) * 0.02,\n",
    "            f\"${value:.2f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=10,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "    # Plot 2: Cost per query\n",
    "    ax2 = axes[1]\n",
    "    cost_per_query = (\n",
    "        df_costs.groupby(\"platform\")[\"total_cost\"].sum() / df_costs.groupby(\"platform\")[\"successful_queries\"].sum()\n",
    "    ).sort_values()\n",
    "\n",
    "    bars = ax2.barh(range(len(cost_per_query)), cost_per_query.values, color=colors, alpha=0.8)\n",
    "    ax2.set_yticks(range(len(cost_per_query)))\n",
    "    ax2.set_yticklabels([p.capitalize() for p in cost_per_query.index])\n",
    "    ax2.set_xlabel(\"Cost per Query (USD)\", fontsize=11)\n",
    "    ax2.set_title(\"Cost Efficiency by Platform\\n(Lower is Better)\", fontsize=12, fontweight=\"bold\")\n",
    "    ax2.grid(axis=\"x\", alpha=0.3)\n",
    "\n",
    "    # Add value labels\n",
    "    for bar, value in zip(bars, cost_per_query.values):\n",
    "        ax2.text(\n",
    "            value + max(cost_per_query.values) * 0.02,\n",
    "            bar.get_y() + bar.get_height() / 2,\n",
    "            f\"${value:.6f}\",\n",
    "            va=\"center\",\n",
    "            fontsize=10,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{config['output_dir']}/cost_breakdown.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"üíæ Saved: {config['output_dir']}/cost_breakdown.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cost Projections and Extrapolation\n",
    "\n",
    "Project costs for different usage scenarios based on benchmark data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_monthly_cost(platform: str, cost_per_query: float, queries_per_day: int) -> Dict:\n",
    "    \"\"\"Project monthly costs based on daily query volume.\n",
    "\n",
    "    Args:\n",
    "        platform: Platform name\n",
    "        cost_per_query: Average cost per query\n",
    "        queries_per_day: Expected daily query volume\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with cost projections\n",
    "    \"\"\"\n",
    "    daily_cost = cost_per_query * queries_per_day\n",
    "    monthly_cost = daily_cost * 30\n",
    "    yearly_cost = monthly_cost * 12\n",
    "\n",
    "    return {\n",
    "        \"platform\": platform,\n",
    "        \"queries_per_day\": queries_per_day,\n",
    "        \"cost_per_query\": cost_per_query,\n",
    "        \"daily_cost\": daily_cost,\n",
    "        \"monthly_cost\": monthly_cost,\n",
    "        \"yearly_cost\": yearly_cost,\n",
    "    }\n",
    "\n",
    "\n",
    "# Define usage scenarios\n",
    "scenarios = [\n",
    "    {\"name\": \"Light (100 queries/day)\", \"queries_per_day\": 100},\n",
    "    {\"name\": \"Moderate (500 queries/day)\", \"queries_per_day\": 500},\n",
    "    {\"name\": \"Heavy (1,000 queries/day)\", \"queries_per_day\": 1000},\n",
    "    {\"name\": \"Enterprise (5,000 queries/day)\", \"queries_per_day\": 5000},\n",
    "]\n",
    "\n",
    "if len(df_costs) > 0:\n",
    "    projections = []\n",
    "\n",
    "    for scenario in scenarios:\n",
    "        print(f\"\\nüìä {scenario['name']} Usage Scenario\")\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "        for platform in df_costs[\"platform\"].unique():\n",
    "            platform_data = df_costs[df_costs[\"platform\"] == platform]\n",
    "            avg_cost_per_query = platform_data[\"total_cost\"].sum() / platform_data[\"successful_queries\"].sum()\n",
    "\n",
    "            projection = project_monthly_cost(platform, avg_cost_per_query, scenario[\"queries_per_day\"])\n",
    "            projection[\"scenario\"] = scenario[\"name\"]\n",
    "            projections.append(projection)\n",
    "\n",
    "            print(f\"  {platform.capitalize()}:\")\n",
    "            print(f\"    Daily: ${projection['daily_cost']:.2f}\")\n",
    "            print(f\"    Monthly: ${projection['monthly_cost']:.2f}\")\n",
    "            print(f\"    Yearly: ${projection['yearly_cost']:.2f}\")\n",
    "\n",
    "    df_projections = pd.DataFrame(projections)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Insufficient data for projections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Cost projections across scenarios\n",
    "if len(df_costs) > 0 and \"df_projections\" in locals():\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    platforms = df_projections[\"platform\"].unique()\n",
    "    scenario_names = [s[\"name\"] for s in scenarios]\n",
    "    x = np.arange(len(scenario_names))\n",
    "    width = 0.8 / len(platforms)\n",
    "\n",
    "    colors = {\"databricks\": \"#FF3621\", \"bigquery\": \"#4285F4\", \"snowflake\": \"#29B5E8\", \"redshift\": \"#CC0000\"}\n",
    "\n",
    "    for i, platform in enumerate(platforms):\n",
    "        platform_data = df_projections[df_projections[\"platform\"] == platform]\n",
    "        monthly_costs = platform_data[\"monthly_cost\"].values\n",
    "\n",
    "        bars = ax.bar(\n",
    "            x + i * width,\n",
    "            monthly_costs,\n",
    "            width,\n",
    "            label=platform.capitalize(),\n",
    "            color=colors.get(platform, \"#888888\"),\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"Usage Scenario\", fontsize=12)\n",
    "    ax.set_ylabel(\"Projected Monthly Cost (USD)\", fontsize=12)\n",
    "    ax.set_title(\"Monthly Cost Projections by Platform and Usage\", fontsize=14, fontweight=\"bold\", pad=15)\n",
    "    ax.set_xticks(x + width * (len(platforms) - 1) / 2)\n",
    "    ax.set_xticklabels(scenario_names, rotation=15, ha=\"right\")\n",
    "    ax.legend(loc=\"upper left\")\n",
    "    ax.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "    # Add budget line if configured\n",
    "    if config[\"budget\"][\"monthly_limit\"] > 0:\n",
    "        ax.axhline(\n",
    "            config[\"budget\"][\"monthly_limit\"],\n",
    "            color=\"red\",\n",
    "            linestyle=\"--\",\n",
    "            linewidth=2,\n",
    "            alpha=0.7,\n",
    "            label=f\"Budget Limit (${config['budget']['monthly_limit']:.0f})\",\n",
    "        )\n",
    "        ax.legend(loc=\"upper left\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{config['output_dir']}/cost_projections.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"üíæ Saved: {config['output_dir']}/cost_projections.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Budget Tracking and Alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_budget_status(df_costs: pd.DataFrame, budget_config: Dict) -> Dict:\n",
    "    \"\"\"Check current spending against budget limits.\"\"\"\n",
    "\n",
    "    # Calculate spending for current month\n",
    "    now = datetime.now()\n",
    "    month_start = datetime(now.year, now.month, 1)\n",
    "\n",
    "    if \"timestamp\" in df_costs.columns:\n",
    "        monthly_costs = df_costs[df_costs[\"timestamp\"] >= month_start]\n",
    "    else:\n",
    "        monthly_costs = df_costs  # Use all data if no timestamps\n",
    "\n",
    "    total_monthly_spend = monthly_costs[\"total_cost\"].sum()\n",
    "    monthly_limit = budget_config[\"monthly_limit\"]\n",
    "    alert_threshold = budget_config[\"alert_threshold\"]\n",
    "\n",
    "    spend_pct = (total_monthly_spend / monthly_limit) * 100 if monthly_limit > 0 else 0\n",
    "    remaining = monthly_limit - total_monthly_spend\n",
    "\n",
    "    alert_level = None\n",
    "    if spend_pct >= 100:\n",
    "        alert_level = \"CRITICAL\"\n",
    "    elif spend_pct >= alert_threshold * 100:\n",
    "        alert_level = \"WARNING\"\n",
    "    else:\n",
    "        alert_level = \"OK\"\n",
    "\n",
    "    return {\n",
    "        \"total_spend\": total_monthly_spend,\n",
    "        \"budget_limit\": monthly_limit,\n",
    "        \"remaining\": remaining,\n",
    "        \"spend_pct\": spend_pct,\n",
    "        \"alert_level\": alert_level,\n",
    "        \"days_in_month\": (now - month_start).days + 1,\n",
    "    }\n",
    "\n",
    "\n",
    "if len(df_costs) > 0:\n",
    "    budget_status = check_budget_status(df_costs, config[\"budget\"])\n",
    "\n",
    "    print(\"üí∞ Budget Status\\n\")\n",
    "    print(f\"Monthly Limit: ${budget_status['budget_limit']:.2f}\")\n",
    "    print(f\"Current Spend: ${budget_status['total_spend']:.2f} ({budget_status['spend_pct']:.1f}%)\")\n",
    "    print(f\"Remaining: ${budget_status['remaining']:.2f}\")\n",
    "    print(f\"Days Elapsed: {budget_status['days_in_month']}\")\n",
    "\n",
    "    # Alert status\n",
    "    alert_emoji = {\"OK\": \"‚úÖ\", \"WARNING\": \"‚ö†Ô∏è\", \"CRITICAL\": \"üö®\"}\n",
    "    print(f\"\\nAlert Level: {alert_emoji[budget_status['alert_level']]} {budget_status['alert_level']}\")\n",
    "\n",
    "    if budget_status[\"alert_level\"] == \"WARNING\":\n",
    "        print(\"\\n‚ö†Ô∏è  Warning: Approaching budget limit!\")\n",
    "        print(f\"   You've used {budget_status['spend_pct']:.1f}% of your monthly budget.\")\n",
    "    elif budget_status[\"alert_level\"] == \"CRITICAL\":\n",
    "        print(\"\\nüö® CRITICAL: Budget exceeded!\")\n",
    "        print(f\"   You've exceeded your budget by ${-budget_status['remaining']:.2f}.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No cost data available for budget tracking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cost Optimization Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cost_optimization_recommendations(df_costs: pd.DataFrame, config: Dict) -> List[str]:\n",
    "    \"\"\"Generate platform-specific cost optimization recommendations.\"\"\"\n",
    "\n",
    "    recommendations = []\n",
    "\n",
    "    for platform in df_costs[\"platform\"].unique():\n",
    "        platform_data = df_costs[df_costs[\"platform\"] == platform]\n",
    "        total_cost = platform_data[\"total_cost\"].sum()\n",
    "\n",
    "        recommendations.append(f\"\\n**{platform.capitalize()}** (${total_cost:.2f} spent)\")\n",
    "\n",
    "        if platform == \"databricks\":\n",
    "            avg_dbu = platform_data[\"dbu_consumption\"].mean()\n",
    "            recommendations.append(f\"  ‚Ä¢ Average DBU consumption: {avg_dbu:.2f} per run\")\n",
    "            recommendations.append(\"  ‚Ä¢ Consider: Use Photon for up to 3x faster queries (fewer DBUs)\")\n",
    "            recommendations.append(\"  ‚Ä¢ Consider: Enable auto-termination to avoid idle cluster costs\")\n",
    "            recommendations.append(\"  ‚Ä¢ Consider: Use Spot instances for non-critical workloads (60-70% savings)\")\n",
    "\n",
    "        elif platform == \"bigquery\":\n",
    "            avg_tb = platform_data[\"tb_processed\"].mean() if \"tb_processed\" in platform_data else 0\n",
    "            recommendations.append(f\"  ‚Ä¢ Average data processed: {avg_tb:.4f} TB per run\")\n",
    "            recommendations.append(\"  ‚Ä¢ Consider: Partition tables by date to reduce data scanned\")\n",
    "            recommendations.append(\"  ‚Ä¢ Consider: Use clustering for frequently filtered columns\")\n",
    "            recommendations.append(\"  ‚Ä¢ Consider: Switch to flat-rate pricing if processing >400TB/month\")\n",
    "\n",
    "        elif platform == \"snowflake\":\n",
    "            warehouse_size = (\n",
    "                platform_data[\"warehouse_size\"].mode()[0] if \"warehouse_size\" in platform_data else \"X-Small\"\n",
    "            )\n",
    "            avg_credits = platform_data[\"credits_consumed\"].mean() if \"credits_consumed\" in platform_data else 0\n",
    "            recommendations.append(f\"  ‚Ä¢ Warehouse size: {warehouse_size}\")\n",
    "            recommendations.append(f\"  ‚Ä¢ Average credits: {avg_credits:.4f} per run\")\n",
    "            recommendations.append(\"  ‚Ä¢ Consider: Enable auto-suspend (1 minute idle recommended)\")\n",
    "            recommendations.append(\"  ‚Ä¢ Consider: Use result caching for repeated queries (free)\")\n",
    "            recommendations.append(\"  ‚Ä¢ Consider: Right-size warehouse (try smaller size for light workloads)\")\n",
    "\n",
    "        elif platform == \"redshift\":\n",
    "            node_type = platform_data[\"node_type\"].mode()[0] if \"node_type\" in platform_data else \"unknown\"\n",
    "            recommendations.append(f\"  ‚Ä¢ Node type: {node_type}\")\n",
    "            recommendations.append(\"  ‚Ä¢ Consider: Use reserved instances for predictable workloads (40-75% savings)\")\n",
    "            recommendations.append(\"  ‚Ä¢ Consider: Pause clusters when not in use\")\n",
    "            recommendations.append(\"  ‚Ä¢ Consider: RA3 nodes with managed storage for cost flexibility\")\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "if len(df_costs) > 0:\n",
    "    print(\"üí° Cost Optimization Recommendations\\n\")\n",
    "    recommendations = generate_cost_optimization_recommendations(df_costs, config)\n",
    "\n",
    "    for rec in recommendations:\n",
    "        print(rec)\n",
    "\n",
    "    print(\"\\nüéØ General Recommendations:\")\n",
    "    print(\"  ‚Ä¢ Use local platforms (DuckDB) for development and testing\")\n",
    "    print(\"  ‚Ä¢ Monitor query performance to identify optimization opportunities\")\n",
    "    print(\"  ‚Ä¢ Set up automated budget alerts in your cloud provider\")\n",
    "    print(\"  ‚Ä¢ Review and optimize expensive queries regularly\")\n",
    "    print(\"  ‚Ä¢ Consider multi-cloud strategy for cost arbitrage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Cost Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export comprehensive cost report\n",
    "if len(df_costs) > 0:\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # 1. Export detailed costs to CSV\n",
    "    costs_file = f\"{config['output_dir']}/cost_details_{timestamp}.csv\"\n",
    "    df_costs.to_csv(costs_file, index=False)\n",
    "    print(f\"‚úÖ Exported cost details: {costs_file}\")\n",
    "\n",
    "    # 2. Export projections to CSV\n",
    "    if \"df_projections\" in locals():\n",
    "        projections_file = f\"{config['output_dir']}/cost_projections_{timestamp}.csv\"\n",
    "        df_projections.to_csv(projections_file, index=False)\n",
    "        print(f\"‚úÖ Exported projections: {projections_file}\")\n",
    "\n",
    "    # 3. Export summary report to JSON\n",
    "    report = {\n",
    "        \"timestamp\": timestamp,\n",
    "        \"platforms\": list(df_costs[\"platform\"].unique()),\n",
    "        \"total_runs\": len(df_costs),\n",
    "        \"total_cost\": float(df_costs[\"total_cost\"].sum()),\n",
    "        \"platform_costs\": df_costs.groupby(\"platform\")[\"total_cost\"].sum().to_dict(),\n",
    "        \"budget_status\": budget_status if \"budget_status\" in locals() else None,\n",
    "        \"recommendations\": recommendations if \"recommendations\" in locals() else [],\n",
    "    }\n",
    "\n",
    "    report_file = f\"{config['output_dir']}/cost_report_{timestamp}.json\"\n",
    "    with open(report_file, \"w\") as f:\n",
    "        json.dump(report, f, indent=2, default=str)\n",
    "\n",
    "    print(f\"‚úÖ Exported cost report: {report_file}\")\n",
    "    print(f\"\\nüìÅ All reports saved to: {config['output_dir']}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No data to export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_costs) > 0:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"üí∞ COST ANALYSIS SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    print(f\"\\nTotal Benchmark Runs: {len(df_costs)}\")\n",
    "    print(f\"Total Cost: ${df_costs['total_cost'].sum():.2f}\")\n",
    "    print(f\"Average Cost per Run: ${df_costs['total_cost'].mean():.4f}\")\n",
    "\n",
    "    print(\"\\nüí∞ Platform Costs:\")\n",
    "    for platform, cost in df_costs.groupby(\"platform\")[\"total_cost\"].sum().sort_values(ascending=False).items():\n",
    "        pct = (cost / df_costs[\"total_cost\"].sum()) * 100\n",
    "        print(f\"  {platform.capitalize()}: ${cost:.2f} ({pct:.1f}%)\")\n",
    "\n",
    "    # Most cost-effective platform\n",
    "    cost_per_query = (\n",
    "        df_costs.groupby(\"platform\")\n",
    "        .apply(lambda x: x[\"total_cost\"].sum() / x[\"successful_queries\"].sum())\n",
    "        .sort_values()\n",
    "    )\n",
    "\n",
    "    print(f\"\\nüèÜ Most Cost-Effective: {cost_per_query.index[0].capitalize()}\")\n",
    "    print(f\"   ${cost_per_query.iloc[0]:.6f} per query\")\n",
    "\n",
    "    if \"budget_status\" in locals():\n",
    "        print(f\"\\nüìä Budget Status: {budget_status['alert_level']}\")\n",
    "        print(f\"   {budget_status['spend_pct']:.1f}% of monthly budget used\")\n",
    "\n",
    "    print(f\"\\nüìÅ Reports exported to: {config['output_dir']}\")\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No cost data available for summary\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
